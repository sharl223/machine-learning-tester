import streamlit as st
import pandas as pd
import lightgbm as lgb
import optuna
import shap
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.metrics import r2_score, accuracy_score
from sklearn.preprocessing import LabelEncoder
import numpy as np
import matplotlib.pyplot as plt
#import japanize_matplotlib
from io import BytesIO
#from ydata_profiling import ProfileReport
#from streamlit_pandas_profiling import st_profile_report

# --- ãƒšãƒ¼ã‚¸ã®åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="LightGBM Playground", page_icon="ğŸš€", layout="wide")

# SHAPãƒ—ãƒ­ãƒƒãƒˆã‚’Streamlitã§è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (æ–‡å­—è‰²ä¿®æ­£ç‰ˆ)
def st_shap(plot, height=None):
    custom_style = """
    <style>
        /* ãƒ†ã‚­ã‚¹ãƒˆãƒ©ãƒ™ãƒ«ã®è‰²ã¨ãƒ•ã‚©ãƒ³ãƒˆ */
        div[id^='shap-force-plot-'] {
            color: #FFFFFF !important;
            font-family: 'M PLUS Rounded 1c', sans-serif !important;
        }
        /* è»¸ã®ã€Œæ•°å€¤ã€ã®è‰²ã‚’å¤‰æ›´ */
        .tick text {
            fill: #FFFFFF !important;
        }
        /* è»¸ã®ã€Œç·šã€ã®è‰²ã‚’å¤‰æ›´ */
        .tick line, .domain {
            stroke: #FFFFFF !important;
        }
    </style>
    """
    shap_html = f"<head>{shap.getjs()}{custom_style}</head><body>{plot.html()}</body>"
    st.components.v1.html(shap_html, height=height)

# --- ãƒ‡ã‚¶ã‚¤ãƒ³ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º ---
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=M+PLUS+Rounded+1c&display=swap');
[data-testid="stAppViewContainer"] > .main {
    background-image: linear-gradient(-45deg, #051937, #004d7a, #008793, #00bf72, #a8eb12);
    background-size: 400% 400%; animation: gradient-animation 15s ease infinite;
}
@keyframes gradient-animation {
    0% { background-position: 0% 50%; } 50% { background-position: 100% 50%; } 100% { background-position: 0% 50%; }
}
[data-testid="stSidebar"] > div:first-child, [data-testid="stVerticalBlockBorderWrapper"] {
    background: rgba(255, 255, 255, 0.1); backdrop-filter: blur(10px);
    box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
    border: 1px solid rgba(255, 255, 255, 0.18); border-radius: 16px;
}
[data-testid="stVerticalBlockBorderWrapper"] { padding: 24px; }
button[data-testid="stButton"] > button {
    transition: transform 0.2s ease, box-shadow 0.2s ease; box-shadow: 0 2px 4px rgba(0,0,0,0.2);
}
button[data-testid="stButton"] > button:hover {
    transform: scale(1.05); box-shadow: 0 4px 12px rgba(0,0,0,0.3);
}
html, body, [class*="st-"], [class*="css-"] { font-family: 'M PLUS Rounded 1c', sans-serif; }
h1, h2, h3, h4, h5, h6 { color: #FFFFFF; word-break: keep-all !important; }
[data-testid="stSidebar"] label { color: #FFFFFF !important; }
[data-testid="stMetric"] { text-align: center; }
[data-testid="stMetric"] [data-testid="stMetricLabel"] p { font-size: 0.9rem !important; }
[data-testid="stMetric"] [data-testid="stMetricValue"] { font-size: 1.75rem !important; }
</style>
""", unsafe_allow_html=True)


# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
st.title("ğŸš€ LightGBM ãƒ—ãƒ¬ã‚¤ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰")
st.write("ã“ã“ã§ã¯ã€ã‚ãªãŸã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦AIäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’è‚²ã¦ã€ãã®æ€§èƒ½ã‚’è©¦ã™ã“ã¨ãŒã§ãã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.header("âš™ï¸ è¨­å®š")
st.sidebar.subheader("1. å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿")
uploaded_file = st.sidebar.file_uploader("å­¦ç¿’ç”¨ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=['csv'])

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if 'best_params' not in st.session_state:
    st.session_state.best_params = {}
if 'profile_report' not in st.session_state:
    st.session_state.profile_report = None

if uploaded_file is not None:
    if 'last_uploaded_file' not in st.session_state or st.session_state.last_uploaded_file != uploaded_file.name:
        st.session_state.profile_report = None
        st.session_state.best_params = {}
        st.session_state.last_uploaded_file = uploaded_file.name
        
    df = pd.read_csv(uploaded_file, index_col=0)
    
    with st.container(border=True):
        st.header("1. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df.head())
        '''
        st.header("2. ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã®è‡ªå‹•åˆ†æ")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ/å†è¡¨ç¤º", help="ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã€æ¬ æå€¤ã€ç›¸é–¢ãªã©ã‚’è©³ç´°ã«åˆ†æã—ã¾ã™ã€‚"):
                with st.spinner("ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­ã§ã™..."):
                    profile = ProfileReport(df, title="ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ", explorative=True)
                    st.session_state.profile_report = profile
                    st.rerun()
        with col2:
            if st.session_state.profile_report is not None:
                if st.button("ãƒ¬ãƒãƒ¼ãƒˆã‚’éš ã™"):
                    st.session_state.profile_report = None
                    st.rerun()

    if st.session_state.profile_report is not None:
        with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ (ã‚¯ãƒªãƒƒã‚¯ã§é–‹é–‰)", expanded=True):
            st.markdown("""
            #### ğŸ“– ãƒ¬ãƒãƒ¼ãƒˆã®èª­ã¿æ–¹ã‚¬ã‚¤ãƒ‰
            ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€ã‚ãªãŸã®ãƒ‡ãƒ¼ã‚¿ã®ã€Œå¥åº·è¨ºæ–­æ›¸ã€ã§ã™ã€‚æ©Ÿæ¢°å­¦ç¿’ã‚’å§‹ã‚ã‚‹å‰ã«ã€ãƒ‡ãƒ¼ã‚¿ãŒã©ã®ã‚ˆã†ãªçŠ¶æ…‹ã‹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚
            """)
            st.markdown("##### 1. æ¦‚è¦ (Overview)")
            st.write("""
            ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ã§ã™ã€‚ã¾ãšã¯ã“ã“ã§å…¨ä½“åƒã‚’æ´ã¿ã¾ã™ã€‚
            - **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ**:
                - `Number of variables (åˆ—æ•°)` / `Number of observations (è¡Œæ•°)`: ãƒ‡ãƒ¼ã‚¿ã®è¦æ¨¡ãŒæƒ³å®šé€šã‚Šã‹ç¢ºèªã—ã¾ã™ã€‚
                - `Missing cells (æ¬ æå€¤)`: ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã§ã€ã©ã‚Œãã‚‰ã„å€¤ãŒæ¬ ã‘ã¦ã„ã‚‹ã‹ã®å‰²åˆã§ã™ã€‚ã“ã®å€¤ãŒé«˜ã„å ´åˆã€æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚
                - `Duplicate rows (é‡è¤‡è¡Œ)`: å…¨ãåŒã˜è¡ŒãŒã„ãã¤ã‚ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚æ„å›³ã—ãªã„é‡è¤‡ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®å¯¾è±¡ã«ãªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
            """)
            st.markdown("##### 2. å„å¤‰æ•°ã®è©³ç´° (Variables)")
            st.write("""
            å„åˆ—ï¼ˆå¤‰æ•°ï¼‰ã”ã¨ã®ã€ã‚ˆã‚Šè©³ç´°ãªåˆ†æçµæœã§ã™ã€‚ã“ã“ãŒåˆ†æã®ãƒ¡ã‚¤ãƒ³ã«ãªã‚Šã¾ã™ã€‚
            - **ã€æ•°å€¤å¤‰æ•°ã§è¦‹ã‚‹ã¹ãç‚¹ã€‘**:
                - `mean (å¹³å‡)`, `min (æœ€å°)`, `max (æœ€å¤§)`: å€¤ãŒç¾å®Ÿçš„ãªç¯„å›²ã«åã¾ã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ï¼ˆä¾‹ï¼šå¹´é½¢ãŒ200æ­³ã«ãªã£ã¦ã„ãªã„ã‹ï¼‰ã€‚æ¥µç«¯ãªã€Œå¤–ã‚Œå€¤ã€ã‚’ç™ºè¦‹ã™ã‚‹æ‰‹ãŒã‹ã‚Šã«ãªã‚Šã¾ã™ã€‚
                - `Histogram (åˆ†å¸ƒå›³)`: ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã®å½¢ã‚’ç¢ºèªã—ã¾ã™ã€‚å±±ãŒä¸€ã¤ã®ç¶ºéº—ãªå½¢ã‹ã€å·¦å³ã«åã£ã¦ã„ã‚‹ã‹ã€äºŒã¤ä»¥ä¸Šã®å±±ãŒã‚ã‚‹ã‹ãªã©ã€ãƒ‡ãƒ¼ã‚¿ã®å€‹æ€§ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚
            - **ã€è³ªçš„å¤‰æ•°ã§è¦‹ã‚‹ã¹ãç‚¹ã€‘**:
                - `Categories (ã‚«ãƒ†ã‚´ãƒªã®ç¨®é¡ã¨æ•°)`: ã©ã®ã‚ˆã†ãªã‚«ãƒ†ã‚´ãƒªãŒå­˜åœ¨ã—ã€ä½•ç¨®é¡ã‚ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚
                - `Bar chart (æ£’ã‚°ãƒ©ãƒ•)`: å„ã‚«ãƒ†ã‚´ãƒªã®å‡ºç¾å›æ•°ã§ã™ã€‚ç‰¹å®šã®ã‚«ãƒ†ã‚´ãƒªã«ãƒ‡ãƒ¼ã‚¿ãŒæ¥µç«¯ã«åã£ã¦ã„ã‚‹ã€Œä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã€ã§ãªã„ã‹ã‚’ç¢ºèªã§ãã¾ã™ã€‚
            """)
            st.markdown("##### 3. ç›¸é–¢ (Correlations)")
            st.write("""
            å¤‰æ•°åŒå£«ã®é–¢ä¿‚ã®å¼·ã•ã‚’ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆè‰²ã®æ¿ƒæ·¡ã§è¡¨ç¾ã—ãŸè¡¨ï¼‰ã§ç¤ºã—ã¾ã™ã€‚
            - **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ**:
                - **ç›®çš„å¤‰æ•°ã¨ã®ç›¸é–¢**: ã‚ãªãŸãŒäºˆæ¸¬ã—ãŸã„ã€Œç›®çš„å¤‰æ•°ã€ã®è¡Œï¼ˆã¾ãŸã¯åˆ—ï¼‰ã‚’è¦‹ã¦ã€ç‰¹ã«è‰²ãŒæ¿ƒã„ï¼ˆèµ¤ã‚„é’ï¼‰å¤‰æ•°ã‚’è¦‹ã¤ã‘ã¾ã—ã‚‡ã†ã€‚ãã‚Œã‚‰ã¯ã€äºˆæ¸¬ã®é‡è¦ãªæ‰‹ãŒã‹ã‚Šã«ãªã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚
                - **èª¬æ˜å¤‰æ•°åŒå£«ã®ç›¸é–¢**: èª¬æ˜å¤‰æ•°åŒå£«ã§ã€éå¸¸ã«è‰²ãŒæ¿ƒã„ï¼ˆç›¸é–¢ä¿‚æ•°ãŒ0.9ä»¥ä¸Šãªã©ï¼‰ãƒšã‚¢ã¯ãªã„ã‹ç¢ºèªã—ã¾ã™ã€‚å¼·ã™ãã‚‹ç›¸é–¢ã‚’æŒã¤ãƒšã‚¢ã¯ã€ä¼¼ãŸã‚ˆã†ãªæƒ…å ±ã‚’æŒã£ã¦ãŠã‚Šã€ç‰‡æ–¹ã‚’å­¦ç¿’ã‹ã‚‰é™¤å¤–ã™ã‚‹å€™è£œã«ãªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼ˆå¤šé‡å…±ç·šæ€§ï¼‰ã€‚
            """)
            st.markdown("##### 4. æ¬ æå€¤ (Missing values)")
            st.write("""
            ã©ã®åˆ—ã®ã€ã©ã®ã‚ãŸã‚Šã«ãƒ‡ãƒ¼ã‚¿ãŒæ¬ ã‘ã¦ã„ã‚‹ã‹ã‚’è¦–è¦šçš„ã«ç¤ºã—ã¾ã™ã€‚
            - **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ**:
                - æ¬ æãŒç‰¹å®šã®åˆ—ã«é›†ä¸­ã—ã¦ã„ãªã„ã‹ã€ãã‚Œã¨ã‚‚å…¨ä½“çš„ã«ã¾ã°ã‚‰ã«ç™ºç”Ÿã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚
                - ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã§ã¯æ¬ æå€¤ã¯ä¿®æ­£ã•ã‚Œã¾ã›ã‚“ãŒã€å¾Œã®æ©Ÿæ¢°å­¦ç¿’ã§ã€Œã“ã®åˆ—ã®æ¬ æã¯ã©ã†æ‰±ãŠã†ã‹ã€ã¨è€ƒãˆã‚‹ãŸã‚ã®é‡è¦ãªæƒ…å ±ã«ãªã‚Šã¾ã™ã€‚
            """)
            st.write("---")
            st_profile_report(st.session_state.profile_report)
            '''
            
    st.write("---")
    st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ãŸã‚‰ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å­¦ç¿’ã®è¨­å®šã‚’è¡Œãªã£ã¦ãã ã•ã„ã€‚", icon="ğŸ‘‡")
    
    st.sidebar.subheader("2. ç›®çš„å¤‰æ•°ã¨å•é¡Œã‚¿ã‚¤ãƒ—ã®é¸æŠ")
    all_columns = df.columns.tolist()
    target_column = st.sidebar.selectbox('ç›®çš„å¤‰æ•°ã‚’é¸ã‚“ã§ãã ã•ã„', all_columns)
    is_numeric = pd.api.types.is_numeric_dtype(df[target_column])
    default_index = 0 if is_numeric else 1
    user_choice = st.sidebar.radio("ã“ã®ã‚¿ã‚¹ã‚¯ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„", ('å›å¸°', 'åˆ†é¡'), index=default_index, horizontal=True)
    problem_type = 'regression' if user_choice == 'å›å¸°' else 'classification'
    
    st.sidebar.subheader("3. èª¬æ˜å¤‰æ•°ã®é¸æŠ")
    feature_columns = st.sidebar.multiselect(
        'äºˆæ¸¬ã«ä½¿ã†é …ç›®ï¼ˆèª¬æ˜å¤‰æ•°ï¼‰ã‚’é¸ã‚“ã§ãã ã•ã„', all_columns,
        default=[col for col in all_columns if col != target_column]
    )
    
    st.sidebar.subheader("4. è³ªçš„å¤‰æ•°ã®æŒ‡å®š (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
    categorical_features_auto = [col for col in feature_columns if df[col].dtype == 'object']
    categorical_features_final = st.sidebar.multiselect(
        'è³ªçš„å¤‰æ•°ã¨ã—ã¦æ‰±ã†åˆ—ã‚’é¸ã‚“ã§ãã ã•ã„', options=feature_columns, default=categorical_features_auto,
        help="æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã§ã‚‚IDã‚„ãƒ©ãƒ³ã‚¯ç­‰ã‚’è¡¨ã™å ´åˆã¯ã“ã“ã§é¸æŠã—ã¦ãã ã•ã„ã€‚"
    )

    st.sidebar.subheader("5. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´")
    with st.sidebar.expander("ğŸ”½ æ‰‹å‹•èª¿æ•´", expanded=True):
        learning_rate = st.number_input('å­¦ç¿’ç‡', 0.01, 1.0, st.session_state.best_params.get('learning_rate', 0.1), 0.01)
        n_estimators = st.slider('æœ¨ã®æ•°', 50, 1000, st.session_state.best_params.get('n_estimators', 100), 50)
        max_depth = st.slider('æœ¨ã®æ·±ã•', 3, 50, st.session_state.best_params.get('max_depth', 7), 1)
        num_leaves = st.slider('è‘‰ã®æ•°', 10, 100, st.session_state.best_params.get('num_leaves', 31), 1)
        subsample = st.slider('è¡Œã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡', 0.1, 1.0, st.session_state.best_params.get('subsample', 0.8), 0.1)
        colsample_bytree = st.slider('åˆ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡', 0.1, 1.0, st.session_state.best_params.get('colsample_bytree', 0.8), 0.1)
        reg_lambda = st.number_input('L2æ­£å‰‡åŒ–', 0.0, 10.0, st.session_state.best_params.get('reg_lambda', 1.0), 0.1)
        reg_alpha = st.number_input('L1æ­£å‰‡åŒ–', 0.0, 10.0, st.session_state.best_params.get('reg_alpha', 0.0), 0.1)
    
    st.sidebar.subheader("6. å­¦ç¿’ã®å®Ÿè¡Œ")
    cv_splits = st.sidebar.slider('äº¤å·®æ¤œè¨¼ã®åˆ†å‰²æ•° (CV splits)', min_value=3, max_value=10, value=5, step=1)

    with st.sidebar.expander("ğŸ¤– ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æœ€é©åŒ– (Optuna)"):
        n_trials = st.number_input("è©¦è¡Œå›æ•° (Trials)", 10, 1000, 50, 10, help="OptunaãŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’è©¦ã™å›æ•°ã§ã™ã€‚")
        if st.button("æœ€é©åŒ–ã‚¹ã‚¿ãƒ¼ãƒˆ", key="optuna_run", help="æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’è‡ªå‹•ã§æ¢ç´¢ã—ã¾ã™ã€‚"):
            
            def objective(trial, X_data, y_data):
                params = {
                    'random_state': 42,
                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                    'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),
                    'max_depth': trial.suggest_int('max_depth', 3, 15),
                    'num_leaves': trial.suggest_int('num_leaves', 20, 50),
                    'subsample': trial.suggest_float('subsample', 0.6, 1.0, step=0.1),
                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0, step=0.1),
                    'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),
                    'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True),
                    'verbose': -1
                }
                scores = []
                le_obj = LabelEncoder()
                if problem_type == 'classification':
                    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
                    y_encoded = le_obj.fit_transform(y_data)
                    y_for_split = y_encoded
                else:
                    kfold = KFold(n_splits=5, shuffle=True, random_state=42)
                    y_for_split = y_data

                for train_index, val_index in kfold.split(X_data, y_for_split):
                    X_train, X_val = X_data.iloc[train_index], X_data.iloc[val_index]
                    y_train_fold, y_val_fold = y_data.iloc[train_index], y_data.iloc[val_index]
                    
                    if problem_type == 'regression':
                        model = lgb.LGBMRegressor(**params); model.fit(X_train, y_train_fold)
                        score = r2_score(y_val_fold, model.predict(X_val))
                    else:
                        le_fold = LabelEncoder(); y_train_encoded_fold = le_fold.fit_transform(y_train_fold)
                        model = lgb.LGBMClassifier(**params); model.fit(X_train, y_train_encoded_fold)
                        y_val_encoded_fold = le_fold.transform(y_val_fold); score = accuracy_score(y_val_encoded_fold, model.predict(X_val))
                    scores.append(score)
                return np.mean(scores)

            with st.spinner(f"{n_trials}å›ã®è©¦è¡Œã§æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ç´¢ä¸­..."):
                features_to_use_for_optuna = feature_columns.copy()
                if target_column in features_to_use_for_optuna: features_to_use_for_optuna.remove(target_column)
                
                X_for_optuna = df[features_to_use_for_optuna].copy()
                y_for_optuna = df[target_column]
                for col in categorical_features_final:
                    if col in X_for_optuna.columns: X_for_optuna[col] = X_for_optuna[col].astype('category')
                
                study = optuna.create_study(direction='maximize')
                progress_bar = st.progress(0, text="æœ€é©åŒ–ã®é€²æ—")
                status_text = st.empty()
                def callback(study, trial):
                    progress = (trial.number + 1) / n_trials
                    progress_bar.progress(progress)
                    status_text.text(f"Trial {trial.number+1}/{n_trials} | æœ€æ–°ã‚¹ã‚³ã‚¢: {trial.value:.4f}")
                
                study.optimize(lambda trial: objective(trial, X_for_optuna, y_for_optuna), n_trials=n_trials, callbacks=[callback])
            
            st.session_state.best_params = study.best_params
            st.success(f"æœ€é©åŒ–å®Œäº†ï¼ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {study.best_value:.4f}")
            st.info("è¦‹ã¤ã‹ã£ãŸæœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã€Œæ‰‹å‹•èª¿æ•´ã€ã®å„é …ç›®ã«ã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸã€‚")
            st.rerun()

    st.sidebar.markdown("---")
    if st.sidebar.button('âœ¨ å­¦ç¿’ã‚¹ã‚¿ãƒ¼ãƒˆ (æ‰‹å‹•è¨­å®š)', key="manual_run"):
        with st.spinner('äº¤å·®æ¤œè¨¼ã¨æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å®Ÿè¡Œä¸­ã§ã™...'):
            features_to_use_manual = feature_columns.copy()
            if target_column in features_to_use_manual:
                features_to_use_manual.remove(target_column)
                st.warning(f"èª¬æ˜å¤‰æ•°ã‹ã‚‰ç›®çš„å¤‰æ•° '{target_column}' ã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚")
            
            X = df[features_to_use_manual].copy()
            y = df[target_column]
            for col in categorical_features_final:
                if col in X.columns: X[col] = X[col].astype('category')

            params = {
                'random_state': 42, 'learning_rate': learning_rate, 'n_estimators': n_estimators,
                'max_depth': max_depth, 'num_leaves': num_leaves, 'subsample': subsample,
                'colsample_bytree': colsample_bytree, 'reg_lambda': reg_lambda, 'reg_alpha': reg_alpha
            }

            scores = []
            le = LabelEncoder()
            if problem_type == 'classification':
                kfold = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)
                y_encoded = le.fit_transform(y)
                y_for_split = y_encoded
            else:
                kfold = KFold(n_splits=cv_splits, shuffle=True, random_state=42)
                y_for_split = y

            for fold, (train_index, val_index) in enumerate(kfold.split(X, y_for_split)):
                X_train, X_val = X.iloc[train_index], X.iloc[val_index]
                y_train, y_val = y.iloc[train_index], y.iloc[val_index]
                if problem_type == 'regression':
                    model_cv = lgb.LGBMRegressor(**params, verbose=-1)
                    model_cv.fit(X_train, y_train)
                    score = r2_score(y_val, model_cv.predict(X_val))
                else:
                    le_fold = LabelEncoder()
                    y_train_encoded_fold = le_fold.fit_transform(y_train)
                    y_val_encoded_fold = le_fold.transform(y_val)
                    model_cv = lgb.LGBMClassifier(**params, verbose=-1)
                    model_cv.fit(X_train, y_train_encoded_fold)
                    score = accuracy_score(y_val_encoded_fold, model_cv.predict(X_val))
                scores.append(score)
            
            if problem_type == 'regression':
                final_model = lgb.LGBMRegressor(**params)
                final_model.fit(X, y)
            else:
                final_model = lgb.LGBMClassifier(**params)
                final_model.fit(X, y_encoded)
                st.session_state['label_encoder'] = le

            fig, ax = plt.subplots(figsize=(12, 10))
            lgb.plot_importance(final_model, ax=ax, importance_type='gain', max_num_features=20)
            ax.tick_params(axis='y', labelsize=21)
            plt.tight_layout()

            st.session_state['model'] = final_model
            st.session_state['target_column'] = target_column
            st.session_state['problem_type'] = problem_type
            st.session_state['cv_scores'] = scores
            st.session_state['feature_columns'] = features_to_use_manual
            st.session_state['categorical_features'] = categorical_features_final
            st.session_state['feature_importance_fig'] = fig
            
            # å¤ã„äºˆæ¸¬çµæœã‚’å‰Šé™¤
            if 'df_predict_with_results' in st.session_state:
                del st.session_state['df_predict_with_results']
            if 'prediction_score_metric' in st.session_state:
                del st.session_state['prediction_score_metric']
            
            st.balloons()
        
if 'cv_scores' in st.session_state:
    st.write("---")
    st.header("ğŸ“ ãƒ¢ãƒ‡ãƒ«ã®æˆç¸¾è¡¨")
    mean_score = np.mean(st.session_state['cv_scores'])
    std_score = np.std(st.session_state['cv_scores'])
    score_metric_name = "å¹³å‡ æ±ºå®šä¿‚æ•° (R2)" if st.session_state['problem_type'] == 'regression' else "å¹³å‡ æ­£è§£ç‡ (Accuracy)"
    st.metric(score_metric_name, f"{mean_score:.4f}", f"Â± {std_score:.4f} (æ¨™æº–åå·®)")
    with st.expander("å„åˆ†å‰²ã§ã®è©³ç´°ã‚¹ã‚³ã‚¢ã‚’è¦‹ã‚‹"):
        scores = st.session_state['cv_scores']
        chart_data = pd.DataFrame({"Score": scores}, index=[f"Fold {i+1}" for i in range(len(scores))])
        st.bar_chart(chart_data, y="Score", height=300)
        score_text = ", ".join([f"Fold {i+1}: {score:.4f}" for i, score in enumerate(scores)])
        st.caption(score_text)

if 'feature_importance_fig' in st.session_state:
    st.header("ğŸ”‘ äºˆæ¸¬ã®ã‚«ã‚®ã¨ãªã£ãŸæƒ…å ±")
    st.pyplot(st.session_state['feature_importance_fig'])

# --- äºˆæ¸¬ãƒ‘ãƒ¼ãƒˆ ---
if 'model' in st.session_state:
    st.write("---")
    st.header("ğŸ”® æœªæ¥ã‚’äºˆæ¸¬ã—ã¦ã¿ã‚ˆã†ï¼")
    
    predict_file = st.file_uploader("äºˆæ¸¬ã—ãŸã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=['csv'], key='predict')

    if predict_file is not None:
        df_predict_original = pd.read_csv(predict_file, index_col=0)
        
        if st.button('ğŸš€ äºˆæ¸¬ã‚’å®Ÿè¡Œ'):
            with st.spinner('äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã€AIã®æ€è€ƒå›è·¯ã‚’åˆ†æä¸­ã§ã™...'):
                model = st.session_state['model']
                feature_columns = st.session_state['feature_columns']
                categorical_features = st.session_state['categorical_features']
                problem_type = st.session_state['problem_type']
                target_column = st.session_state.get('target_column')

                X_pred = df_predict_original[feature_columns].copy()
                for col in categorical_features:
                    if col in X_pred.columns:
                        X_pred[col] = X_pred[col].astype('category')
                
                prediction_raw = model.predict(X_pred)
                df_predict_result = df_predict_original.copy()

                if problem_type == 'classification':
                    le = st.session_state['label_encoder']
                    prediction = le.inverse_transform(prediction_raw)
                else:
                    prediction = prediction_raw
                
                df_predict_result['äºˆæ¸¬çµæœ'] = prediction

                if target_column and target_column in df_predict_result.columns:
                    y_true = df_predict_result[target_column]
                    if problem_type == 'classification':
                        score = accuracy_score(y_true, prediction)
                        st.session_state['prediction_score_metric'] = ("æ­£è§£ç‡ (Accuracy)", f"{score:.4f}")
                    else:
                        score = r2_score(y_true, prediction)
                        st.session_state['prediction_score_metric'] = ("æ±ºå®šä¿‚æ•° (R2 Score)", f"{score:.4f}")
                    
                    cols = df_predict_result.columns.tolist()
                    cols.insert(cols.index('äºˆæ¸¬çµæœ') + 1, cols.pop(cols.index(target_column)))
                    df_predict_result = df_predict_result[cols]
                else:
                    if 'prediction_score_metric' in st.session_state:
                        del st.session_state['prediction_score_metric']

                explainer = shap.TreeExplainer(model)
                shap_values = explainer.shap_values(X_pred)
                
                st.session_state['df_predict_with_results'] = df_predict_result
                st.session_state['shap_explainer'] = explainer
                st.session_state['shap_values'] = shap_values
                st.session_state['X_pred_for_shap'] = X_pred
                st.rerun()

    if 'prediction_score_metric' in st.session_state:
        metric_label, metric_value = st.session_state['prediction_score_metric']
        st.metric(label=f"ğŸ¯ äºˆæ¸¬ã®ç­”ãˆåˆã‚ã›çµæœ", value=metric_value, help=f"äºˆæ¸¬çµæœã¨ã€Œ{metric_label}ã€ã®æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒã—ãŸã‚¹ã‚³ã‚¢ã§ã™ã€‚")

    if 'df_predict_with_results' in st.session_state:
        st.subheader("äºˆæ¸¬çµæœ")
        st.dataframe(st.session_state['df_predict_with_results'])
        
        @st.cache_data
        def convert_df(df):
            return df.to_csv(encoding='utf-8-sig').encode('utf-8-sig')

        csv = convert_df(st.session_state['df_predict_with_results'])
        st.download_button(
            label="äºˆæ¸¬çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name='prediction_results.csv',
            mime='text/csv',
        )
        
        if 'shap_values' in st.session_state:
            st.write("---")
            st.subheader("å€‹åˆ¥ã®äºˆæ¸¬ã®ã€Œç†ç”±ã€ã‚’åˆ†æ (SHAP)")
            
            shap_target_index = st.selectbox(
                "åˆ†æã—ãŸã„è¡Œã®ç•ªå·ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„",
                options=st.session_state['X_pred_for_shap'].index
            )
            
            if shap_target_index is not None:
                explainer = st.session_state['shap_explainer']
                shap_values = st.session_state['shap_values']
                X_pred_for_shap = st.session_state['X_pred_for_shap']
                shap_target_iloc = X_pred_for_shap.index.get_loc(shap_target_index)

                st.markdown("""
                <div style="padding: 1rem; border: 1px solid rgba(255, 255, 255, 0.2); border-radius: 10px;">
                <h5>ğŸ“ˆ ã‚°ãƒ©ãƒ•ã®èª­ã¿æ–¹</h5>
                <p>ã“ã®ã‚°ãƒ©ãƒ•ã¯ã€AIã®äºˆæ¸¬çµæœï¼ˆ<span style="color: #ff0d57;"><b>èµ¤è‰²</b></span>ã®å¤ªå­—ï¼‰ã«å¯¾ã—ã¦ã€ã©ã®æƒ…å ±ãŒã©ã®ã‚ˆã†ã«å½±éŸ¿ã—ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚</p>
                <ul>
                    <li><b style="color: #ff0d57;">ãƒ—ãƒ©ã‚¹ã«åƒã„ãŸæƒ…å ±ï¼ˆèµ¤è‰²ï¼‰</b>ï¼šäºˆæ¸¬å€¤ã‚’æŠ¼ã—ä¸Šã’ã‚‹æ–¹å‘ã«å½±éŸ¿ã—ã¾ã—ãŸã€‚</li>
                    <li><b style="color: #008bfb;">ãƒã‚¤ãƒŠã‚¹ã«åƒã„ãŸæƒ…å ±ï¼ˆé’è‰²ï¼‰</b>ï¼šäºˆæ¸¬å€¤ã‚’æŠ¼ã—ä¸‹ã’ã‚‹æ–¹å‘ã«å½±éŸ¿ã—ã¾ã—ãŸã€‚</li>
                </ul>
                <p><code>base value</code>ã¯ã€ä½•ã‚‚æƒ…å ±ãŒãªã„ã¨ãã®å¹³å‡çš„ãªäºˆæ¸¬å€¤ã§ã™ã€‚</p>
                </div>
                """, unsafe_allow_html=True)
                st.write("")

                if st.session_state['problem_type'] == 'classification':
                    if isinstance(shap_values, list):
                        st.info("åˆ†é¡å•é¡Œã§ã¯ã€é™½æ€§ã‚¯ãƒ©ã‚¹ï¼ˆä¾‹: Survived=1ï¼‰ã«å¯¾ã™ã‚‹å„ç‰¹å¾´é‡ã®å½±éŸ¿åº¦ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                        st_shap(shap.force_plot(
                            explainer.expected_value[1],
                            shap_values[1][shap_target_iloc],
                            X_pred_for_shap.iloc[shap_target_iloc]
                        ))
                    else:
                        st.info("åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã«å¯¾ã™ã‚‹å„ç‰¹å¾´é‡ã®å½±éŸ¿åº¦ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                        st_shap(shap.force_plot(
                            explainer.expected_value,
                            shap_values[shap_target_iloc],
                            X_pred_for_shap.iloc[shap_target_iloc]
                        ))
                else:
                    st_shap(shap.force_plot(
                        explainer.expected_value,
                        shap_values[shap_target_iloc],
                        X_pred_for_shap.iloc[shap_target_iloc]
                    ))

else:
    with st.expander("ğŸ¤” ã‚¢ãƒ—ãƒªã®ä½¿ã„ã‹ãŸã‚¬ã‚¤ãƒ‰", expanded=True):
        st.markdown("""
        ### 1. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        - äºˆæ¸¬ã—ãŸã„ã€Œç­”ãˆã€ã®åˆ—ã‚’å«ã‚€ã€CSVå½¢å¼ã®å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ã”ç”¨æ„ãã ã•ã„ã€‚
        - å¿…è¦ã§ã‚ã‚Œã°ã€ã€Œã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç½®ãå ´ã€ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠä½¿ã„ã„ãŸã ã‘ã¾ã™ã€‚
        ### 2. ãƒ‡ãƒ¼ã‚¿ã¨è¨­å®š
        - ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œå‚ç…§ã€ãƒœã‚¿ãƒ³ã‹ã‚‰ã€å­¦ç¿’ç”¨CSVãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
        - **ç›®çš„å¤‰æ•°**: äºˆæ¸¬ã—ãŸã„ã€Œç­”ãˆã€ã®åˆ—ã‚’æŒ‡å®šã—ã¾ã™ã€‚
        - **ã‚¿ã‚¹ã‚¯ã®ç¨®é¡**: ç›®çš„å¤‰æ•°ãŒæ•°å€¤ãªã‚‰ã€Œå›å¸°ã€ã€ã‚«ãƒ†ã‚´ãƒªãªã‚‰ã€Œåˆ†é¡ã€ã‚’é¸ã³ã¾ã™ã€‚
        - **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ–¹æ³•ã‚’ç´°ã‹ãèª¿æ•´ã§ãã¾ã™ã€‚ã¾ãŸã¯ã€Œè‡ªå‹•æœ€é©åŒ–ã€ã§AIã«æ¢ã•ã›ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚
        - **èª¬æ˜å¤‰æ•°**: äºˆæ¸¬ã®æ‰‹ãŒã‹ã‚Šã¨ãªã‚‹åˆ—ã‚’é¸ã³ã¾ã™ã€‚
        - **è³ªçš„å¤‰æ•°**: èª¬æ˜å¤‰æ•°ã®ä¸­ã§ã€æ•°å€¤ã§ã‚‚ã‚«ãƒ†ã‚´ãƒªã¨ã—ã¦æ‰±ã„ãŸã„åˆ—ãŒã‚ã‚Œã°æŒ‡å®šã—ã¾ã™ã€‚
        ### 3. å­¦ç¿’ã¨åˆ†æ
        - ã€Œå­¦ç¿’ã‚¹ã‚¿ãƒ¼ãƒˆã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨å­¦ç¿’ãŒå§‹ã¾ã‚Šã¾ã™ã€‚
        - **ãƒ¢ãƒ‡ãƒ«ã®æˆç¸¾è¡¨**: ä½œæˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è³¢ã•ã‚’ç¤ºã™ã‚¹ã‚³ã‚¢ã§ã™ã€‚
        - **äºˆæ¸¬ã®ã‚«ã‚®ã¨ãªã£ãŸæƒ…å ±**: ã©ã®å¤‰æ•°ãŒäºˆæ¸¬ã«é‡è¦ã ã£ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚
        ### 4. æœªæ¥ã®äºˆæ¸¬
        - ã€Œæœªæ¥ã‚’äºˆæ¸¬ã—ã¦ã¿ã‚ˆã†ï¼ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã€ç­”ãˆã®åˆ—ãŒãªã„æ–°ã—ã„CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
        """)